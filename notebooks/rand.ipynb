{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "from pathlib import Path\n",
    "from MetaLifeLongLanguage.datasets.text_classification_dataset import AGNewsDataset, get_dataset, get_datasets\n",
    "from MetaLifeLongLanguage.datasets.utils import batch_encode\n",
    "import hydra\n",
    "from hydra.experimental import compose, initialize\n",
    "from torch.utils.data import DataLoader\n",
    "from omegaconf import OmegaConf\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "from train_text_cls import get_learner\n",
    "\n",
    "from omegaconf import DictConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pprint\n",
    "\n",
    "from MetaLifeLongLanguage.learner import flatten_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = Path(\"../experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {}\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment in sorted(list(experiment_dir.glob(\"*\")), key=lambda x: x.name):\n",
    "    if \"evaluate\" in experiment.name:\n",
    "        continue\n",
    "    learner_type = experiment.name.split(\"=\")[1].split(\"_\")[0]\n",
    "\n",
    "    experiments[learner_type] = experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agem': PosixPath('../experiments/learner=agem_2021-01-27_17-43-27'),\n",
       " 'anml': PosixPath('../experiments/learner=anml_2021-01-28_20-32-16'),\n",
       " 'multitask': PosixPath('../experiments/learner=multitask_2021-01-27_17-44-25'),\n",
       " 'oml': PosixPath('../experiments/learner=oml_2021-01-27_17-44-59'),\n",
       " 'replay': PosixPath('../experiments/learner=replay_2021-01-27_17-44-28'),\n",
       " 'sequential': PosixPath('../experiments/learner=sequential_2021-01-28_19-24-50')}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for learner_type, experiment in experiments.items():\n",
    "    validation_results = experiment / \"results\" / \"validation_results.csv\"\n",
    "    test_results = experiment / \"results\" / \"test_results.csv\"\n",
    "    results[learner_type] = {}\n",
    "    results[learner_type][\"validation\"] = pd.read_csv(validation_results)\n",
    "    results[learner_type][\"test\"] = pd.read_csv(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agem': {'test':             Unnamed: 0  accuracy  precision    recall        f1\n",
      "0          YelpDataset  0.006711   0.347101  0.006682  0.012846\n",
      "1        AGNewsDataset  0.000000   0.000000  0.000000  0.000000\n",
      "2       DBPediaDataset  0.000000   0.000000  0.000000  0.000000\n",
      "3        AmazonDataset  0.003947   0.369612  0.003989  0.007788\n",
      "4  YahooAnswersDataset  0.766974   0.769986  0.767470  0.766515,\n",
      "          'validation':             Unnamed: 0  accuracy  precision    recall        f1\n",
      "0          YelpDataset  0.004474   0.300275  0.004602  0.008941\n",
      "1        AGNewsDataset  0.000000   0.000000  0.000000  0.000000\n",
      "2       DBPediaDataset  0.000000   0.000000  0.000000  0.000000\n",
      "3        AmazonDataset  0.004474   0.245455  0.004350  0.008475\n",
      "4  YahooAnswersDataset  0.776447   0.774746  0.769984  0.770710},\n",
      " 'anml': {'test':             Unnamed: 0  accuracy  precision    recall        f1\n",
      "0          YelpDataset  0.577105   0.614890  0.577786  0.591347\n",
      "1        AGNewsDataset  0.857368   0.905065  0.857368  0.874709\n",
      "2       DBPediaDataset  0.987895   0.990738  0.987968  0.989338\n",
      "3        AmazonDataset  0.559474   0.617771  0.559071  0.576377\n",
      "4  YahooAnswersDataset  0.762105   0.768792  0.759810  0.760424,\n",
      "          'validation':             Unnamed: 0  accuracy  precision    recall        f1\n",
      "0          YelpDataset  0.598026   0.633459  0.597337  0.611041\n",
      "1        AGNewsDataset  0.863947   0.906141  0.864553  0.877994\n",
      "2       DBPediaDataset  0.988816   0.991185  0.988927  0.990036\n",
      "3        AmazonDataset  0.563947   0.621296  0.563883  0.584114\n",
      "4  YahooAnswersDataset  0.755395   0.759612  0.747770  0.748599},\n",
      " 'multitask': {'test':             Unnamed: 0  accuracy  precision    recall        f1\n",
      "0          YelpDataset  0.659211   0.660723  0.660134  0.659175\n",
      "1        AGNewsDataset  0.930658   0.934933  0.930658  0.932569\n",
      "2       DBPediaDataset  0.988421   0.988661  0.988322  0.988458\n",
      "3        AmazonDataset  0.624737   0.621827  0.625148  0.621045\n",
      "4  YahooAnswersDataset  0.769737   0.772737  0.769149  0.765517,\n",
      "               'validation':             Unnamed: 0  accuracy  precision    recall        f1\n",
      "0          YelpDataset  0.736711   0.738165  0.736816  0.736700\n",
      "1        AGNewsDataset  0.965526   0.967189  0.965082  0.966005\n",
      "2       DBPediaDataset  0.993553   0.993688  0.993675  0.993664\n",
      "3        AmazonDataset  0.700132   0.698739  0.701848  0.697625\n",
      "4  YahooAnswersDataset  0.841711   0.841520  0.835185  0.833443},\n",
      " 'oml': {'test':             Unnamed: 0  accuracy  precision    recall        f1\n",
      "0          YelpDataset  0.598158   0.621175  0.599186  0.607921\n",
      "1        AGNewsDataset  0.848553   0.894375  0.848553  0.866904\n",
      "2       DBPediaDataset  0.986447   0.988100  0.986620  0.987324\n",
      "3        AmazonDataset  0.572500   0.612963  0.572120  0.587238\n",
      "4  YahooAnswersDataset  0.744737   0.757772  0.740334  0.738937,\n",
      "         'validation':             Unnamed: 0  accuracy  precision    recall        f1\n",
      "0          YelpDataset  0.611053   0.630098  0.610722  0.618898\n",
      "1        AGNewsDataset  0.856711   0.899225  0.856802  0.872970\n",
      "2       DBPediaDataset  0.986711   0.988669  0.986832  0.987707\n",
      "3        AmazonDataset  0.571447   0.609116  0.571889  0.588478\n",
      "4  YahooAnswersDataset  0.740658   0.747729  0.730474  0.730348},\n",
      " 'replay': {'test':             Unnamed: 0  accuracy  precision    recall        f1\n",
      "0          YelpDataset  0.503289   0.610167  0.505137  0.543362\n",
      "1        AGNewsDataset  0.363947   0.863930  0.363947  0.451653\n",
      "2       DBPediaDataset  0.966447   0.985344  0.966963  0.975516\n",
      "3        AmazonDataset  0.503026   0.613915  0.503228  0.550580\n",
      "4  YahooAnswersDataset  0.768026   0.769329  0.768974  0.768006,\n",
      "            'validation':             Unnamed: 0  accuracy  precision    recall        f1\n",
      "0          YelpDataset  0.512368   0.614936  0.512857  0.551050\n",
      "1        AGNewsDataset  0.349342   0.876084  0.351294  0.437036\n",
      "2       DBPediaDataset  0.973158   0.987797  0.973611  0.980277\n",
      "3        AmazonDataset  0.520658   0.638890  0.522011  0.570596\n",
      "4  YahooAnswersDataset  0.774868   0.773225  0.770458  0.770805},\n",
      " 'sequential': {'test':             Unnamed: 0  accuracy  precision    recall        f1\n",
      "0          YelpDataset  0.010395   0.315785  0.010324  0.019713\n",
      "1        AGNewsDataset  0.000000   0.000000  0.000000  0.000000\n",
      "2       DBPediaDataset  0.000132   0.071429  0.000132  0.000263\n",
      "3        AmazonDataset  0.014474   0.331008  0.014513  0.027284\n",
      "4  YahooAnswersDataset  0.768947   0.770002  0.770624  0.768736,\n",
      "                'validation':             Unnamed: 0  accuracy  precision    recall        f1\n",
      "0          YelpDataset  0.010263   0.295037  0.010385  0.019819\n",
      "1        AGNewsDataset  0.000000   0.000000  0.000000  0.000000\n",
      "2       DBPediaDataset  0.000658   0.142857  0.000664  0.001319\n",
      "3        AmazonDataset  0.018289   0.388695  0.017931  0.033632\n",
      "4  YahooAnswersDataset  0.783289   0.780877  0.779023  0.778539}}\n"
     ]
    }
   ],
   "source": [
    "pp = pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15552631578947368"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"agem\"][\"test\"].accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for learner_type, learner_type_results in results.items():\n",
    "    data[learner_type] = learner_type_results[\"test\"].accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agem': 0.15552631578947368,\n",
       " 'anml': 0.7487894736842104,\n",
       " 'multitask': 0.7945526315789475,\n",
       " 'oml': 0.7500789473684211,\n",
       " 'replay': 0.6209473684210526,\n",
       " 'sequential': 0.15878947368421054}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame.from_dict({key: {\"accuracy\": round(value * 100, 2)} for key, value in data.items()}, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>agem</th>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anml</th>\n",
       "      <td>74.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multitask</th>\n",
       "      <td>79.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oml</th>\n",
       "      <td>75.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>replay</th>\n",
       "      <td>62.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequential</th>\n",
       "      <td>15.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy\n",
       "agem           15.55\n",
       "anml           74.88\n",
       "multitask      79.46\n",
       "oml            75.01\n",
       "replay         62.09\n",
       "sequential     15.88"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sequential</th>\n",
       "      <td>15.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agem</th>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>replay</th>\n",
       "      <td>62.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oml</th>\n",
       "      <td>75.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anml</th>\n",
       "      <td>74.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multitask</th>\n",
       "      <td>79.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy\n",
       "sequential     15.88\n",
       "agem           15.55\n",
       "replay         62.09\n",
       "oml            75.01\n",
       "anml           74.88\n",
       "multitask      79.46"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.loc[[\"sequential\", \"agem\", \"replay\", \"oml\", \"anml\", \"multitask\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MetaLifeLongLanguage.models.cls_agem import AGEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"AGNews\": {\n",
    "        \"acc\": 0.8,\n",
    "        \"f1\": 0.5\n",
    "    },\n",
    "    \"DBPedia\": {\n",
    "        \"acc\": 0.9,\n",
    "        \"f1\": 0.6\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame.from_dict(results, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGNews</th>\n",
       "      <th>DBPedia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AGNews  DBPedia\n",
       "acc     0.8      0.9\n",
       "f1      0.5      0.6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[\"mean\"] = r.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/omarelb/projects/thesis/code/notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(seed, version, **kwargs):\n",
    "    other_fn(kwargs)\n",
    "    print(seed, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_fn(kwargs):\n",
    "    print(DictConfig(kwargs).inference)\n",
    "#     print(kwargs.inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "42 0\n"
     ]
    }
   ],
   "source": [
    "f(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of MetaLifeLongLanguage.models.cls_agem failed: Traceback (most recent call last):\n",
      "  File \"/home/omarelb/projects/thesis/code/venv/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/omarelb/projects/thesis/code/venv/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/omarelb/projects/thesis/code/venv/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/omarelb/projects/thesis/code/venv/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/home/omarelb/projects/thesis/code/venv/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/omarelb/projects/thesis/code/venv/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 266, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: __init__() requires a code object with 0 free vars, not 1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "agem = AGEM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AGEM' object has no attribute 'exp_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-0719a9da4d86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'AGEM' object has no attribute 'exp_dir'"
     ]
    }
   ],
   "source": [
    "agem.exp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.name is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hydra:\n",
      "  run:\n",
      "    dir: experiments/${hydra.job.override_dirname}_${now:%Y-%m-%d_%H-%M-%S}_${name}/seed=${seed}\n",
      "  sweep:\n",
      "    dir: experiments/sweep-${name}_${now:%Y-%m-%d_%H-%M-%S}\n",
      "    subdir: ${hydra.job.override_dirname}_${hydra.job.num}\n",
      "  hydra_logging:\n",
      "    version: 1\n",
      "    formatters:\n",
      "      colorlog:\n",
      "        (): colorlog.ColoredFormatter\n",
      "        format: '[%(cyan)s%(asctime)s%(reset)s][%(purple)sHYDRA%(reset)s] %(message)s'\n",
      "    handlers:\n",
      "      console:\n",
      "        class: logging.StreamHandler\n",
      "        formatter: colorlog\n",
      "        stream: ext://sys.stdout\n",
      "    root:\n",
      "      level: INFO\n",
      "      handlers:\n",
      "      - console\n",
      "    disable_existing_loggers: false\n",
      "  job_logging:\n",
      "    version: 1\n",
      "    formatters:\n",
      "      simple:\n",
      "        format: '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'\n",
      "      colorlog:\n",
      "        (): colorlog.ColoredFormatter\n",
      "        format: '[%(cyan)s%(asctime)s%(reset)s][%(blue)s%(name)s%(reset)s][%(log_color)s%(levelname)s%(reset)s]\n",
      "          - %(message)s'\n",
      "        log_colors:\n",
      "          DEBUG: purple\n",
      "          INFO: green\n",
      "          WARNING: yellow\n",
      "          ERROR: red\n",
      "          CRITICAL: red\n",
      "    handlers:\n",
      "      console:\n",
      "        class: logging.StreamHandler\n",
      "        formatter: colorlog\n",
      "        stream: ext://sys.stdout\n",
      "      file:\n",
      "        class: logging.FileHandler\n",
      "        formatter: simple\n",
      "        filename: ${hydra.job.name}.log\n",
      "    root:\n",
      "      level: INFO\n",
      "      handlers:\n",
      "      - console\n",
      "      - file\n",
      "    disable_existing_loggers: false\n",
      "  sweeper:\n",
      "    _target_: hydra._internal.core_plugins.basic_sweeper.BasicSweeper\n",
      "    max_batch_size: null\n",
      "  launcher:\n",
      "    _target_: hydra._internal.core_plugins.basic_launcher.BasicLauncher\n",
      "  help:\n",
      "    app_name: ${hydra.job.name}\n",
      "    header: '${hydra.help.app_name} is powered by Hydra.\n",
      "\n",
      "      '\n",
      "    footer: 'Powered by Hydra (https://hydra.cc)\n",
      "\n",
      "      Use --hydra-help to view Hydra specific help\n",
      "\n",
      "      '\n",
      "    template: '${hydra.help.header}\n",
      "\n",
      "      == Configuration groups ==\n",
      "\n",
      "      Compose your configuration from those groups (group=option)\n",
      "\n",
      "\n",
      "      $APP_CONFIG_GROUPS\n",
      "\n",
      "\n",
      "      == Config ==\n",
      "\n",
      "      Override anything in the config (foo.bar=value)\n",
      "\n",
      "\n",
      "      $CONFIG\n",
      "\n",
      "\n",
      "      ${hydra.help.footer}\n",
      "\n",
      "      '\n",
      "  hydra_help:\n",
      "    hydra_help: ???\n",
      "    template: 'Hydra (${hydra.runtime.version})\n",
      "\n",
      "      See https://hydra.cc for more info.\n",
      "\n",
      "\n",
      "      == Flags ==\n",
      "\n",
      "      $FLAGS_HELP\n",
      "\n",
      "\n",
      "      == Configuration groups ==\n",
      "\n",
      "      Compose your configuration from those groups (For example, append hydra/job_logging=disabled\n",
      "      to command line)\n",
      "\n",
      "\n",
      "      $HYDRA_CONFIG_GROUPS\n",
      "\n",
      "\n",
      "      Use ''--cfg hydra'' to Show the Hydra config.\n",
      "\n",
      "      '\n",
      "  output_subdir: .hydra\n",
      "  overrides:\n",
      "    hydra: []\n",
      "    task:\n",
      "    - learner=agem\n",
      "    - wandb=false\n",
      "  job:\n",
      "    name: notebook\n",
      "    override_dirname: learner=agem\n",
      "    id: ???\n",
      "    num: ???\n",
      "    config_name: defaults\n",
      "    env_set: {}\n",
      "    env_copy: []\n",
      "    config:\n",
      "      override_dirname:\n",
      "        kv_sep: '='\n",
      "        item_sep: ','\n",
      "        exclude_keys:\n",
      "        - name\n",
      "        - wandb\n",
      "        - checkpoint_while_training\n",
      "        - save_freq\n",
      "        - seed\n",
      "  runtime:\n",
      "    version: 1.0.5\n",
      "    cwd: /home/omarelb/projects/thesis/code/notebooks\n",
      "  verbose: false\n",
      "learner:\n",
      "  inner_lr: 0.001\n",
      "  meta_lr: 1.0e-05\n",
      "  type: agem\n",
      "  model_name: bert\n",
      "  lr: 3.0e-05\n",
      "seed: 42\n",
      "inference: false\n",
      "version: 0\n",
      "write_prob: 1.0\n",
      "replay_rate: 0.01\n",
      "replay_every: 9600\n",
      "updates: 5\n",
      "clip_grad_norm: 25\n",
      "checkpoint_while_training: true\n",
      "save_freq: 60\n",
      "wandb: false\n",
      "debug: false\n",
      "name: null\n",
      "data:\n",
      "  order: 1\n",
      "  max_length: 448\n",
      "  n_classes: 33\n",
      "training:\n",
      "  device: cuda\n",
      "  epochs: 1\n",
      "  valid_freq: 100\n",
      "  save_freq: 5000\n",
      "  log_freq: 50\n",
      "  batch_size: 16\n",
      "model:\n",
      "  name: bert\n",
      "\n"
     ]
    }
   ],
   "source": [
    "initialize(config_path=\"../config/\")\n",
    "config = compose(config_name=\"defaults\", overrides=[\"learner=agem\", \"wandb=false\"], return_hydra_config=True)\n",
    "print(OmegaConf.to_yaml(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.hydra.job.num=0\n",
    "config.hydra.job.id = 0\n",
    "config.hydra.hydra_help.hydra_help = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_info = flatten_dict(config)\n",
    "\n",
    "for key in list(run_info.keys()):\n",
    "    if key.startswith(\"hydra\"):\n",
    "        del run_info[key]\n",
    "\n",
    "xx = {\n",
    "    \"accuracy\": 0.7,\n",
    "    \"precision\": 0.8\n",
    "}\n",
    "mean_validation_results = {\"validation_\" + k : v for k, v in xx.items()}\n",
    "\n",
    "for k, v in mean_validation_results.items():\n",
    "    run_info[k] = v\n",
    "\n",
    "run_info[\"finish_time\"] = datetime.datetime.now()\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "if not Path(\"results.csv\").exists():\n",
    "    df = pd.DataFrame()\n",
    "else:\n",
    "    df = pd.read_csv(\"results.csv\")\n",
    "\n",
    "df = df.append(run_info, ignore_index=True)\n",
    "\n",
    "df.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('accuracy', 0.7), ('precision', 0.8), ('accuracy', 0.7), ('precision', 0.8)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(xx.items()) + list(xx.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm results.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkpoint_while_training</th>\n",
       "      <th>clip_grad_norm</th>\n",
       "      <th>data_max_length</th>\n",
       "      <th>data_n_classes</th>\n",
       "      <th>data_order</th>\n",
       "      <th>debug</th>\n",
       "      <th>finish_time</th>\n",
       "      <th>inference</th>\n",
       "      <th>learner_inner_lr</th>\n",
       "      <th>learner_lr</th>\n",
       "      <th>...</th>\n",
       "      <th>training_epochs</th>\n",
       "      <th>training_log_freq</th>\n",
       "      <th>training_save_freq</th>\n",
       "      <th>training_valid_freq</th>\n",
       "      <th>updates</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>validation_precision</th>\n",
       "      <th>version</th>\n",
       "      <th>wandb</th>\n",
       "      <th>write_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-02-02 11:58:24.099765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   checkpoint_while_training  clip_grad_norm  data_max_length  data_n_classes  \\\n",
       "0                        1.0            25.0            448.0            33.0   \n",
       "\n",
       "   data_order  debug                 finish_time  inference  learner_inner_lr  \\\n",
       "0         1.0    0.0  2021-02-02 11:58:24.099765        0.0             0.001   \n",
       "\n",
       "   learner_lr  ...  training_epochs training_log_freq training_save_freq  \\\n",
       "0     0.00003  ...              1.0              50.0             5000.0   \n",
       "\n",
       "  training_valid_freq  updates  validation_accuracy  validation_precision  \\\n",
       "0               100.0      5.0                  0.7                   0.8   \n",
       "\n",
       "   version  wandb  write_prob  \n",
       "0      0.0    0.0         1.0  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2021-02-02 11:51:38.047724\n",
       "Name: time, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learner_inner_lr': 0.001,\n",
       " 'learner_meta_lr': 1e-05,\n",
       " 'learner_type': 'agem',\n",
       " 'learner_model_name': 'bert',\n",
       " 'learner_lr': 3e-05,\n",
       " 'seed': 42,\n",
       " 'inference': False,\n",
       " 'version': 0,\n",
       " 'write_prob': 1.0,\n",
       " 'replay_rate': 0.01,\n",
       " 'replay_every': 9600,\n",
       " 'updates': 5,\n",
       " 'clip_grad_norm': 25,\n",
       " 'checkpoint_while_training': True,\n",
       " 'save_freq': 60,\n",
       " 'wandb': False,\n",
       " 'debug': False,\n",
       " 'name': None,\n",
       " 'data_order': 1,\n",
       " 'data_max_length': 448,\n",
       " 'data_n_classes': 33,\n",
       " 'training_device': 'cuda',\n",
       " 'training_epochs': 1,\n",
       " 'training_valid_freq': 100,\n",
       " 'training_save_freq': 5000,\n",
       " 'training_log_freq': 50,\n",
       " 'training_batch_size': 16,\n",
       " 'model_name': 'bert',\n",
       " 'validation_accuracy': 0.7,\n",
       " 'validation_precision': 0.8}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict({\"name\": [\"hyper\", \"hp2\"], \"id\": [1, 2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hypeeee-1'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"hypeeee\"\n",
    "in_data = (df[\"name\"] == name).any()\n",
    "\n",
    "if in_data:\n",
    "    # increment counter for this experiment name to avoid duplicate names\n",
    "    id = df.loc[df[\"name\"] == name, \"id\"].values[0] + 1\n",
    "    df.loc[df[\"name\"] == name, \"id\"] = id\n",
    "    experiment_id = {\"name\": name, \"id\": id}\n",
    "else:\n",
    "    experiment_id = {\"name\": name, \"id\": 1}\n",
    "    df = df.append(experiment_id, ignore_index=True)\n",
    "\n",
    "f\"{experiment_id['name']}-{experiment_id['id']}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyper</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hp2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hypee</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  id\n",
       "0  hyper   2\n",
       "1    hp2   2\n",
       "2  hypee   1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(EXPERIMENT_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hypee-1'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "Name: name, dtype: bool"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[\"name\"] == \"hp2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-01 12:47:04,594 - MetaLifeLongLanguage.learner - INFO - --------------------------------------------------\n",
      "2021-02-01 12:47:04,597 - MetaLifeLongLanguage.learner - INFO - TRAINING LOG\n",
      "2021-02-01 12:47:04,599 - MetaLifeLongLanguage.learner - INFO - --------------------------------------------------\n",
      "2021-02-01 12:47:04,601 - MetaLifeLongLanguage.learner - INFO - --------------------------------------------------\n",
      "CONFIG:\n",
      "{'hydra': {'run': {'dir': 'experiments/${hydra.job.override_dirname}_${now:%Y-%m-%d_%H-%M-%S}_${name}'}, 'sweep': {'dir': 'experiments/${now:%Y-%m-%d}/${now:%H-%M-%S}', 'subdir': '${hydra.job.override_dirname}_${hydra.job.num}'}, 'hydra_logging': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][HYDRA] %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}}, 'root': {'level': 'INFO', 'handlers': ['console']}, 'loggers': {'logging_example': {'level': 'DEBUG'}}, 'disable_existing_loggers': False}, 'job_logging': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': '${hydra.job.name}.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}, 'sweeper': {'_target_': 'hydra._internal.core_plugins.basic_sweeper.BasicSweeper', 'max_batch_size': None}, 'launcher': {'_target_': 'hydra._internal.core_plugins.basic_launcher.BasicLauncher'}, 'help': {'app_name': '${hydra.job.name}', 'header': '${hydra.help.app_name} is powered by Hydra.\\n', 'footer': 'Powered by Hydra (https://hydra.cc)\\nUse --hydra-help to view Hydra specific help\\n', 'template': '${hydra.help.header}\\n== Configuration groups ==\\nCompose your configuration from those groups (group=option)\\n\\n$APP_CONFIG_GROUPS\\n\\n== Config ==\\nOverride anything in the config (foo.bar=value)\\n\\n$CONFIG\\n\\n${hydra.help.footer}\\n'}, 'hydra_help': {'hydra_help': '???', 'template': \"Hydra (${hydra.runtime.version})\\nSee https://hydra.cc for more info.\\n\\n== Flags ==\\n$FLAGS_HELP\\n\\n== Configuration groups ==\\nCompose your configuration from those groups (For example, append hydra/job_logging=disabled to command line)\\n\\n$HYDRA_CONFIG_GROUPS\\n\\nUse '--cfg hydra' to Show the Hydra config.\\n\"}, 'output_subdir': '.hydra', 'overrides': {'hydra': [], 'task': ['learner=agem', 'wandb=false']}, 'job': {'name': 'notebook', 'override_dirname': 'learner=agem,wandb=false', 'id': '???', 'num': '???', 'config_name': 'defaults', 'env_set': {}, 'env_copy': [], 'config': {'override_dirname': {'kv_sep': '=', 'item_sep': ',', 'exclude_keys': []}}}, 'runtime': {'version': '1.0.5', 'cwd': '/home/omarelb/projects/thesis/code/notebooks'}, 'verbose': False}, 'learner': {'inner_lr': 0.001, 'meta_lr': 1e-05, 'type': 'agem', 'model_name': 'bert', 'lr': 3e-05}, 'seed': 42, 'inference': False, 'version': 0, 'write_prob': 1.0, 'replay_rate': 0.01, 'replay_every': 9600, 'updates': 5, 'clip_grad_norm': 25, 'checkpoint_while_training': True, 'save_freq': 60, 'wandb': False, 'debug': False, 'name': None, 'data': {'order': 1, 'max_length': 448, 'n_classes': 33}, 'training': {'device': 'cuda', 'epochs': 1, 'valid_freq': 100, 'save_freq': 5000, 'log_freq': 50, 'batch_size': 16}, 'model': {'name': 'bert'}}\n",
      "--------------------------------------------------\n",
      "2021-02-01 12:47:04,603 - MetaLifeLongLanguage.learner - INFO - Setting seed: 42\n",
      "2021-02-01 12:47:04,612 - MetaLifeLongLanguage.learner - INFO - Using device: cuda\n",
      "2021-02-01 12:47:05,028 - transformers.tokenization_utils_base - INFO - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/omarelb/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "2021-02-01 12:47:05,475 - transformers.configuration_utils - INFO - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/omarelb/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "2021-02-01 12:47:05,478 - transformers.configuration_utils - INFO - Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "2021-02-01 12:47:05,532 - transformers.modeling_utils - INFO - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/omarelb/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "2021-02-01 12:47:09,716 - transformers.modeling_utils - INFO - All model checkpoint weights were used when initializing BertModel.\n",
      "\n",
      "2021-02-01 12:47:09,718 - transformers.modeling_utils - INFO - All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "2021-02-01 12:47:13,082 - MetaLifeLongLanguage.learner - INFO - Loaded TransformerClsModel as model\n"
     ]
    }
   ],
   "source": [
    "learner = get_learner(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.get_last_checkpoint_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = Path(\"../experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = experiment_dir / \"learner=agem_2021-01-26_15-01-03\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = model_name / '.hydra' / 'config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.wandb = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.3587212562561035"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'learners' in config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-27 15:19:04,299 - MetaLifeLongLanguage.learner - INFO - --------------------------------------------------\n",
      "2021-01-27 15:19:04,301 - MetaLifeLongLanguage.learner - INFO - TRAINING LOG\n",
      "2021-01-27 15:19:04,303 - MetaLifeLongLanguage.learner - INFO - --------------------------------------------------\n",
      "2021-01-27 15:19:04,304 - MetaLifeLongLanguage.learner - INFO - --------------------------------------------------\n",
      "CONFIG:\n",
      "{'learner': {'inner_lr': 0.001, 'meta_lr': 1e-05, 'type': 'agem', 'model_name': 'bert', 'lr': 3e-05}, 'seed': 42, 'inference': False, 'version': 0, 'write_prob': 1.0, 'replay_rate': 0.01, 'replay_every': 9600, 'updates': 5, 'clip_grad_norm': 25, 'wandb': False, 'debug': False, 'data': {'order': 1, 'max_length': 448, 'n_classes': 33}, 'training': {'device': 'cuda', 'epochs': 1, 'valid_freq': 100, 'save_freq': 5000, 'log_freq': 50, 'batch_size': 16}, 'model': {'name': 'bert'}}\n",
      "--------------------------------------------------\n",
      "2021-01-27 15:19:04,305 - MetaLifeLongLanguage.learner - INFO - Setting seed: 42\n",
      "2021-01-27 15:19:04,312 - MetaLifeLongLanguage.learner - INFO - Using device: cuda\n",
      "2021-01-27 15:19:04,714 - transformers.tokenization_utils_base - INFO - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/omarelb/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "2021-01-27 15:19:05,163 - transformers.configuration_utils - INFO - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/omarelb/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "2021-01-27 15:19:05,165 - transformers.configuration_utils - INFO - Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "2021-01-27 15:19:05,263 - transformers.modeling_utils - INFO - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/omarelb/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "2021-01-27 15:19:09,467 - transformers.modeling_utils - INFO - All model checkpoint weights were used when initializing BertModel.\n",
      "\n",
      "2021-01-27 15:19:09,474 - transformers.modeling_utils - INFO - All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "2021-01-27 15:19:12,965 - MetaLifeLongLanguage.learner - INFO - Loaded TransformerClsModel as model\n"
     ]
    }
   ],
   "source": [
    "learner = get_learner(config, experiment_path=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../experiments/learner=agem_2021-01-26_15-01-03/model-checkpoints/Epoch[1]-Step[35625].pt')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.get_last_checkpoint_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-27 15:19:40,454 - MetaLifeLongLanguage.learner - INFO - Loading checkpoint from ../experiments/learner=agem_2021-01-26_15-01-03/model-checkpoints/Epoch[1]-Step[35625].pt\n"
     ]
    }
   ],
   "source": [
    "learner.load_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learner': {'inner_lr': 0.001, 'meta_lr': 1e-05, 'type': 'agem', 'model_name': 'bert', 'lr': 3e-05}, 'seed': 42, 'inference': False, 'version': 0, 'write_prob': 1.0, 'replay_rate': 0.01, 'replay_every': 9600, 'updates': 5, 'clip_grad_norm': 25, 'checkpoint_while_training': True, 'save_freq': 0.25, 'wandb': False, 'debug': False, 'data': {'order': 1, 'max_length': 10, 'n_classes': 33}, 'training': {'device': 'cuda', 'epochs': 1, 'log_freq': 50, 'batch_size': 1}, 'model': {'name': 'bert'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OmegaConf.load('../experiments/learner=agem,save_freq=0.25,training=debug,wandb=false_2021-01-27_16-23-02/.hydra/config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerClsModel(\n",
       "  (encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=768, out_features=33, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-27 15:21:29,466 - root - INFO - Loading data...\n",
      "2021-01-27 15:21:30,792 - root - INFO - Loaded YelpDataset\n",
      "2021-01-27 15:21:31,318 - root - INFO - Loaded AGNewsDataset\n",
      "2021-01-27 15:21:32,112 - root - INFO - Loaded DBPediaDataset\n",
      "2021-01-27 15:21:33,027 - root - INFO - Loaded AmazonDataset\n",
      "2021-01-27 15:21:34,321 - root - INFO - Loaded YahooAnswersDataset\n",
      "2021-01-27 15:21:34,325 - root - INFO - Finished loading all the datasets\n"
     ]
    }
   ],
   "source": [
    "datasets = learner.get_datasets(\"/home/omarelb/projects/thesis/code/data/\", config.data.order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"first of all i'm not a big fan of buffet, i tried it because we got a $ 50 credit for staying here at monte carlo in las vegas and my friend wanted it so i gave it a chance. decent taste and there wasn't enough variety of food, service wasn't that great either. so it still doesn't change my mind about buffet.\",\n",
       " 0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"val\"][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"came a few days ago for a lease, wasn't sure of size needed, so i guessed, three times! finally got it right, but hey, the store didn't bat a eye lash when i returned the ones that didn't work, they just asked if i needed help picking out a replacement. since my cat has been loosing weight, i could not get the size down, so after my attempts, finally got the small dog size and sure enough it worked. now to get the cat used to it before we need it. this store has everything you could need. they is even a new section by martha stewart, everything for you little pet. but her stuffs pricey, a lease from here collection, $ 19.99, boy that's steep! the store is clean, neatly kept, well organized and they have grooming services. the employees were friendly and helpful, they looked like they enjoyed their jobs, and i would make this a regular place.\",\n",
       " 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"test\"][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-27 15:25:42,600 - MetaLifeLongLanguage.learner - INFO - Testing on YelpDataset\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-9dd82270d1a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/thesis/code/MetaLifeLongLanguage/learner.py\u001b[0m in \u001b[0;36mtesting\u001b[0;34m(self, datasets)\u001b[0m\n\u001b[1;32m    131\u001b[0m             test_dataloader = DataLoader(dataset, batch_size=self.mini_batch_size, shuffle=False,\n\u001b[1;32m    132\u001b[0m                                          collate_fn=batch_encode)\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mdataset_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mprecisions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"precision\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/thesis/code/MetaLifeLongLanguage/models/cls_agem.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mall_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner.testing(datasets[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_length = sum([len(train_dataset) for train_dataset in datasets[\"train\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35625"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_length // 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110000,\n",
       " <MetaLifeLongLanguage.datasets.text_classification_dataset.AGNewsDataset at 0x148fe249d4d0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets[\"train\"][1]), datasets[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(datasets[\"train\"], batch_size=learner.mini_batch_size, shuffle=False,\n",
    "                              collate_fn=batch_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-96ab2bd5b5d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'learner' is not defined"
     ]
    }
   ],
   "source": [
    "learner.load_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.mini_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d733c1f55d14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/thesis/code/venv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/thesis/code/venv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/thesis/code/venv/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/thesis/code/MetaLifeLongLanguage/datasets/utils.py\u001b[0m in \u001b[0;36mbatch_encode\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbatch_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "t, l = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-25 16:08:19,905 - ANML-Log - INFO - Replay frequency: 801\n",
      "2021-01-25 16:08:19,907 - ANML-Log - INFO - Replay steps: 48\n",
      "2021-01-25 16:12:32,437 - MetaLifeLongLanguage.learner - INFO - Episode 1 support set: Loss = 3.4020, accuracy = 0.1000, precision = 0.0417, recall = 0.0833, F1 score = 0.0556\n",
      "2021-01-25 16:13:33,026 - ANML-Log - INFO - Episode 1 query set: Loss = 3.2236, accuracy = 0.5000, precision = 0.2500, recall = 0.5000, F1 score = 0.3333\n",
      "2021-01-25 16:15:43,313 - MetaLifeLongLanguage.learner - INFO - Episode 2 support set: Loss = 3.5227, accuracy = 0.0000, precision = 0.0000, recall = 0.0000, F1 score = 0.0000\n"
     ]
    }
   ],
   "source": [
    "learner.training(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<MetaLifeLongLanguage.datasets.text_classification_dataset.DBPediaDataset at 0x14557b140d90>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.YahooAnswersDataset at 0x14557b104f10>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.AGNewsDataset at 0x14562ca9db90>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.AmazonDataset at 0x14557bd7f9d0>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.YelpDataset at 0x14557bd75bd0>],\n",
       " [<MetaLifeLongLanguage.datasets.text_classification_dataset.DBPediaDataset at 0x14557b1405d0>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.YahooAnswersDataset at 0x14557b104c90>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.AGNewsDataset at 0x14562ca9d710>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.AmazonDataset at 0x14557bd7fad0>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.YelpDataset at 0x14557bd754d0>],\n",
       " [<MetaLifeLongLanguage.datasets.text_classification_dataset.DBPediaDataset at 0x14557b1041d0>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.YahooAnswersDataset at 0x14557b1048d0>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.AGNewsDataset at 0x14562ca9dc90>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.AmazonDataset at 0x14557bd75150>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.YelpDataset at 0x14557bd75490>])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_datasets(DATA_PATH, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = DATA_PATH / \"train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(file, header=None, sep=',', names=['labels', 'title', 'description'],\n",
    "                    index_col=False)\n",
    "data['text'] = data['title'] + '. ' + data['description']\n",
    "data['labels'] = data['labels'] - 1\n",
    "data.drop(columns=['title', 'description'], inplace=True)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>0</td>\n",
       "      <td>Pakistan's Musharraf Says Won't Quit as Army C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>1</td>\n",
       "      <td>Renteria signing a top-shelf deal. Red Sox gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>1</td>\n",
       "      <td>Saban not going to Dolphins yet. The Miami Dol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>1</td>\n",
       "      <td>Today's NFL games. PITTSBURGH at NY GIANTS Tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>1</td>\n",
       "      <td>Nets get Carter from Raptors. INDIANAPOLIS -- ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        labels                                               text\n",
       "0            2  Wall St. Bears Claw Back Into the Black (Reute...\n",
       "1            2  Carlyle Looks Toward Commercial Aerospace (Reu...\n",
       "2            2  Oil and Economy Cloud Stocks' Outlook (Reuters...\n",
       "3            2  Iraq Halts Oil Exports from Main Southern Pipe...\n",
       "4            2  Oil prices soar to all-time record, posing new...\n",
       "...        ...                                                ...\n",
       "119995       0  Pakistan's Musharraf Says Won't Quit as Army C...\n",
       "119996       1  Renteria signing a top-shelf deal. Red Sox gen...\n",
       "119997       1  Saban not going to Dolphins yet. The Miami Dol...\n",
       "119998       1  Today's NFL games. PITTSBURGH at NY GIANTS Tim...\n",
       "119999       1  Nets get Carter from Raptors. INDIANAPOLIS -- ...\n",
       "\n",
       "[120000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VAL_SIZE = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TRAIN_SIZE = 115000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TEST_SIZE = 7600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(data, train_size=MAX_TRAIN_SIZE, test_size=MAX_VAL_SIZE, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7168</th>\n",
       "      <td>3</td>\n",
       "      <td>Flying the Sun to Safety. When the Genesis cap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29618</th>\n",
       "      <td>2</td>\n",
       "      <td>Stocks Seen Flat as Nortel and Oil Weigh.  NEW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101425</th>\n",
       "      <td>1</td>\n",
       "      <td>Inter Milan seeks redemption win against Juven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20441</th>\n",
       "      <td>2</td>\n",
       "      <td>Saudi Arabia cuts oil prices. Oil prices eased...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2662</th>\n",
       "      <td>0</td>\n",
       "      <td>Google Cuts Its IPO Price Range. SAN JOSE, Cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20371</th>\n",
       "      <td>2</td>\n",
       "      <td>FOCUS: Santander Says HBOS Counterbid To Face ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108151</th>\n",
       "      <td>3</td>\n",
       "      <td>HP Revises Cluster Plans. HP (Quote, Chart) is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15315</th>\n",
       "      <td>3</td>\n",
       "      <td>Manugistics Fires Its President. Manugistics G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23538</th>\n",
       "      <td>0</td>\n",
       "      <td>US genocide charge is Bush election ploy - Sud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113198</th>\n",
       "      <td>3</td>\n",
       "      <td>Netflix CEO Rates Blockbuster, Amazon Threats ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        labels                                               text\n",
       "7168         3  Flying the Sun to Safety. When the Genesis cap...\n",
       "29618        2  Stocks Seen Flat as Nortel and Oil Weigh.  NEW...\n",
       "101425       1  Inter Milan seeks redemption win against Juven...\n",
       "20441        2  Saudi Arabia cuts oil prices. Oil prices eased...\n",
       "2662         0  Google Cuts Its IPO Price Range. SAN JOSE, Cal...\n",
       "20371        2  FOCUS: Santander Says HBOS Counterbid To Face ...\n",
       "108151       3  HP Revises Cluster Plans. HP (Quote, Chart) is...\n",
       "15315        3  Manugistics Fires Its President. Manugistics G...\n",
       "23538        0  US genocide charge is Bush election ploy - Sud...\n",
       "113198       3  Netflix CEO Rates Blockbuster, Amazon Threats ..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path(os.getcwd()).parent / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = AGNewsDataset(p, \"train\", reduce=True)\n",
    "val = AGNewsDataset(p, \"val\", reduce=True)\n",
    "test = AGNewsDataset(p, \"test\", reduce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('williams contacts dolphins but says he #39;s headed for india. retired running back ricky williams says he contacted the miami dolphins this week at the request of his agent but has no plans to rejoin the team anytime soon.',\n",
       " 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MetaLifeLongLanguage.datasets.utils import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<MetaLifeLongLanguage.datasets.text_classification_dataset.AGNewsDataset at 0x15193c0a6d10>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.AGNewsDataset at 0x15193bc2c6d0>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.AGNewsDataset at 0x15193c4a7e10>),\n",
       " (<MetaLifeLongLanguage.datasets.text_classification_dataset.AmazonDataset at 0x15193c4a77d0>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.AmazonDataset at 0x15193c4a7e90>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.AmazonDataset at 0x151937e07fd0>),\n",
       " (<MetaLifeLongLanguage.datasets.text_classification_dataset.YelpDataset at 0x151937e07c10>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.YelpDataset at 0x151937e05150>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.YelpDataset at 0x151937e051d0>),\n",
       " (<MetaLifeLongLanguage.datasets.text_classification_dataset.DBPediaDataset at 0x15192ba4aed0>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.DBPediaDataset at 0x15192ba4afd0>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.DBPediaDataset at 0x1519290e6f10>),\n",
       " (<MetaLifeLongLanguage.datasets.text_classification_dataset.YahooAnswersDataset at 0x1519290e6e90>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.YahooAnswersDataset at 0x1519290e6e10>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.YahooAnswersDataset at 0x15190c858b90>)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[get_dataset(p, i) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<MetaLifeLongLanguage.datasets.text_classification_dataset.AGNewsDataset at 0x15193c0a6d10>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.AGNewsDataset at 0x15193bc2c6d0>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.AGNewsDataset at 0x15193c4a7e10>),\n",
       " (<MetaLifeLongLanguage.datasets.text_classification_dataset.AmazonDataset at 0x15193c4a77d0>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.AmazonDataset at 0x15193c4a7e90>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.AmazonDataset at 0x151937e07fd0>),\n",
       " (<MetaLifeLongLanguage.datasets.text_classification_dataset.YelpDataset at 0x151937e07c10>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.YelpDataset at 0x151937e05150>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.YelpDataset at 0x151937e051d0>),\n",
       " (<MetaLifeLongLanguage.datasets.text_classification_dataset.DBPediaDataset at 0x15192ba4aed0>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.DBPediaDataset at 0x15192ba4afd0>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.DBPediaDataset at 0x1519290e6f10>),\n",
       " (<MetaLifeLongLanguage.datasets.text_classification_dataset.YahooAnswersDataset at 0x1519290e6e90>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.YahooAnswersDataset at 0x1519290e6e10>,\n",
       "  <MetaLifeLongLanguage.datasets.text_classification_dataset.YahooAnswersDataset at 0x15190c858b90>)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'williams contacts dolphins but says he #39;s headed for india. retired running back ricky williams says he contacted the miami dolphins this week at the request of his agent but has no plans to rejoin the team anytime soon.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
